## Анализ схемы в контексте планирования логирования

### Список необходимых логов уровня INFO в разрезе систем

#### Интернет магазин

- Создание нового заказа:
  - timestamp: ...
  - level: INFO
  - service_name: 'Shop API'
  - event_type: ORDER_CREATED
  - order_id: ...
  - user_id ...
  - прочие данные по необходимости
- Загрузка 3D моделей:
  - timestamp: ...
  - level: INFO
  - service_name: 'Shop API'
  - event_type: FILE_UPLOADED
  - order_id: ...
  - user_id ...
  - file_name ...
  - file_size ...
- Сабмит заказа
  - timestamp: ...
  - level: INFO
  - service_name: 'Shop API'
  - event_type: SUBMITTED
  - order_id: ...
  - user_id ...
  - file_name ... # чтобы не подтягивать потом дополнительно при анализе
  - file_size ... # чтобы не подтягивать потом дополнительно при анализе

#### CRM

- Подтверждение от менеджера
  - timestamp: ...
  - level: INFO
  - service_name: 'CRM API'
  - event_type: MANUFACTURING_APPROVED
  - order_id: ...
  - user_id: ...
  - manager_id: ...
- Заказ завершен
  - timestamp: ...
  - level: INFO
  - service_name: 'CRM API'
  - event_type: CLOSED
  - order_id: ...
  - user_id: ...
  - manager_id: ...

    
#### MES API
- Старт расчета цены
  - timestamp: ...
  - level: INFO
  - service_name: 'MES API'
  - event_type: PRICE_CALCULATION_START
  - order_id: ...
  - user_id: ...
  - file_name: ...
  - file_size: ...
- Цена посчитана
  - timestamp: ...
  - level: INFO
  - service_name: 'MES API'
  - event_type: PRICE_CALCULATED
  - order_id: ...
  - user_id: ...
  - file_name: ...
  - price_calculated: ...
- Оператор взял в работу
  - timestamp: ...
  - level: INFO
  - service_name: 'MES API'
  - event_type: MANUFACTURING_STARTED
  - order_id: ...
  - operator_id: ...
  - file_name: ... # важно знать по какому эскизу начали готовить
- Оператор выполнил заказ
  - timestamp: ...
  - level: INFO
  - service_name: 'MES API'
  - event_type: MANUFACTURING_COMPLETED
  - order_id: ...
  - operator_id: ...
  - file_name: ... # важно знать по какому эскизу подготовили
- Оператор - упаковка
  - timestamp: ...
  - level: INFO
  - service_name: 'MES API'
  - event_type: PACKAGING
  - order_id: ...
  - operator_id: ...
- Оператор - отправил заказ
  - timestamp: ...
  - service_name: 'MES API'
  - event_type: SHIPPED
  - order_id: ...
  - operator_id: ...
- Оператор - запросил список доступных заказов
  - timestamp: ...
  - service_name: 'MES API'
  - event_type: GET_ORDERS
  - operator_id: ...
  - filters: ... # посмотрим какие фильтры ставят чаще всего
  - orders_returned: ... # сколько доступно заказов на исполнение
  - page_number: ... # на какой странице оператор
  - response_time: ... # за сколько мы получили информацию
  - returned_from_cache: ... # было ли попадание в кэщ

#### RabbitMQ
Хочется посмотреть именно на обмен сообщениями между сервисами
- timestamp: ...
- service_name: 'MES API' # или любой кто отправляет / получает сообщения
- event_type: MESSAGE_SENT / MESSAGE_RECEIVED
- queue_name: ...
- order_id: ...

#### S3
можно посмотреть как мы пишем файлы
- timestamp: ...
- service_name: "S3"
- event_type: FILE_UPLOADED / FILE_DOWNLOADED
- file_name: ...

#### Mes DB / CRM DB
Можно включить логирование медленных запросов (например такое есть в postgres и mysql)


### Другие уровни логирования
#### DEEBUG
- для отладки расчета цены в MES API - система считается долго, поэтому полезным будет уровень дебаг
- Для отладки очереди сообщений в RabbitMQ (как быстро сообщения передаются, как быстро обрабатываются, время акноледжа и тд)
- прочие

#### Warn
- для аномальных сценариев, таких как слишком долгого расчета цены (после Х минут) 
- слишком много необработанных сообщений в очереди (после Х штук)
- Неудачные запросы в БД
- прочие

#### Error
- исключения при работе с базами
- ошибки публикации сообщения
- любые исключения, приводящие к 500
- нарушение консистентности данных (например пытаемся менять статус заказа, которого нет в бд)
- прочие

## Мотивация

### Зачем это нужно:
#### Помощь в отслеживании пути заказа при инцидентах
При внедрении в логи такого поля как order_id можно проследить как двигается статус заказа по логам уровня INFO
Это поможет прослеживать заказ при расследовании инцидентов. В каком то смысле это дублирует трейсинг

#### Обнаружение скрытых проблем
Даже если была проблема и никто на нее не пожаловался (например, расчет не сработал, а потом сработал со второго раза),
мы все равно сможем посмотреть на логи уровня Warn/Error и увидеть тонкие места в системе

#### Оптимизация производительности
Благодаря сквозным логам (на самом деле это сильно пересекается с трейсингом и настроенным мониторингом по метрикам),
можно отследить скорость обработки в тех или иных частях системы, что позволит определить какие оптимизации можно провести.

#### Сокращение времени расследования инцидентов
Например, при обращении в службу поддержки, можно посмотреть по логам что происходило с заказом и как-то разобраться
Без логов это было бы практически невозможно


### Технические и бизнес метрики

#### Mean time to resolve
Как быстро команда справляется с инцидентами? Логирование точно улучшит эту метрику, улучшив удовлетворенность клиентов

#### Доля "потерянных" заказов
Поскольку в системе есть проблемы с тормозами заказов, логирование точно поможет разобраться
Возможно даже стоит настроить дополнительные алерты на сонове логов по продвижению заказов, чтобы решать проблемы до того, как на них обратит внимание клиент.
Это скажется на удовлетворенности клиентом от сервиса

#### Количество ошибок работы сервиса
Логирование помогает устранять проблемы. Это повышает надежность работы сервиса и как следствие ведет к улучшению "пропускной способности"
То есть, люди занимаются созданием заказов/работой, а не борьбой с ошибками сервиса, что приводит к положительному финансовому эффекту


### Логирование VS Трейсинг

#### 1 MES API и интеграция через RabbitMQ
Важно внедрить в первую очередь, так как кажется именно в этом месте больше всего проблем с потерей заказов / медленной их обработкой.

Внедряем трейсинг, так как фокус на том как текут сообщения от CRM до MES и обратно.
Для этого в сообщениях надо указывать trace_id, чтобы отслеживать путь сообщений


#### 2 CRM
Тут происходит управление заказами, поэтому важно обеспечить работоспособность, чтобы можно было понимать реальное положение дел по заказам и начать расследование по зависшим заказам до того как все стало слишком плохо.

Внедряем логироваание, так как CRM это больше система фиксирования статуса (то есть транзакционные записи).
Поэтому и логи, а не трейс, так как они тоже по своей сути похожи на "транзакции".
Также например логи хорошо пододят для расследования того кто/когда утвердил заказ (нажал кнопку)

#### 3 Shop API
Важно обеспечить бесперебойную работу сервиса для создания заказов.
Потому что заказ не создан = не оплачен счет = прямые финансовые потери
Не смотря на важность системы, основные проблемы сейчас в пунктах 1 и 2, поэтому приоритет снижен до 3.

Логирование, так как важны фактологические записи (заказ создан / цена посчитана / файл загружен и тд)


#### 4 MES API и работа операторов
Операторы жалуются, что система плохо работает, медленно грузится.
Не смотря на то, что проблема очевидна, операторы - это исполнители заказов (вероятно предоплаченных),
поэтому важнее обеспечить бесперебойную работу по составлению заказов в первую очередь (при ограниченном количестве ресурсов)
Операторы замотивированы продолжать работу с системой, даже если она виснит, так как это их зароботок
Поэтому ускорение работы для операторов менее приоритетно по сравнению с Shop API и всем остальным, что выше

Будет полезно отслеживать 500 статусы при работе с системой, чтобы понять при каких действиях "все плохо"
Для этого также подойдет логирование, так как тут нужно фиксировать факты


### Предлагаемое решение
#### Система сбора и хранения логов

Выш мы определеили, что нужно для разных систем использовать разный подход (логирование vs трейсинг)

Для трейсинга можно использовать OpenTelemetry + Jaeger для "MES API и интеграция через RabbitMQ"

Для остального предлагается использовать централизованное хранилище логов, которое будет реализовано с помощью ELK (Elasticsearch, Logstash, Kibana)
Для сбора логи предлагается использовать Filebeat, который собирает логи из сервисов и отправляет их в Logstash для последующего сохранения в Elasticsearch и анализа с помощью Kibana
Для удобства работы с логами, нужно сформировать единую схему, которая будет использоваться в сервисах

Например, это может быть:
- timestamp
- level
- service_name
- order_id
- user_id
- event
- additional_data


#### Что нужно доработать
Для сбора логов нужно доработать MES API / Shop API / CRM
Нужно внедрить запись логов в определенном формате, а также подключить их сбор и последуюшее хранение с анализом (ELK)


#### Безопасность в отношении логов
- обезличить и маскировать. Не собирать персональные данные или другие чувствительные данные. Если все таки такое нужно собрать, то лучше всего их маскировать (например присваивать фейковый id юзерам, чтобы нельзя было связать с конкретными юзерами напрямую)
- Ограничить доступ к логам. Нужно проработать ролевую систему и доступы. Например для агентов поддержки может давать не стоит полный доступ, а только ограниченный. А техническим специалистам наоборот расширенный доступ
- Шифрование. Можно использовать TLS/HTTPS
- Мониторинг доступа. Вести логи того кто смотрел / когда входил / что смотрел.
- Убедиться в соответствии политикам 152-ФЗ/GDRP

#### Политика хранения логов
- отдельные индексы под каждую систему и под каждое окружение - это упростит фильтрацию
- Установить срок хранения логов (например, 30 дней). Возможно переносить в холодное хранилище с последующим удалением после, например, 90 дней
- сохранять не все уровни логов. Например, в продакшене сохранять INFO и выше (мы ранее указывали что по INFO можно отследить движение)
- также можно установить максимальный размер индекса, который стоит высчитать исходя из объема заказов. Соответственно ротировать при достижении установленного лимита


#### Переход к анализу логов
Чтобы логирование не превратилось в пассивное складирование, нужно наладить автоматический анализ и алертинг с выявлением аномалий.
Для этого нужно:
- формализовать метрики и пороги. Например, превышение ERROR в единицу времени
- настроить алертинг. Например, в elastiksearch можно использовать модуль watcher для настройки правил... например, если количество новых заказов за минуту превысило 500 - писать алерт в тг/слак итд
- Можно использовать алгоритмы выявления аномалий, например на основе модели для временных рядов ARIMA, которые могут подстраиваться под "нормальное" поведение системы и алертить если будут скачки
